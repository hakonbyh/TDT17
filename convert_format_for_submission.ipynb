{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Takes in bounding box data, contatining class\n",
    "   and position and converts it to the correct format\"\"\"\n",
    "\n",
    "def convert_format(data, width, height):\n",
    "    bbox = [float(elem) for elem in data[1:]]\n",
    "    x, y, w, h = bbox\n",
    "    xmin = int((x - w / 2) * width)\n",
    "    ymin = int((y - h / 2) * height)\n",
    "    xmax = int((x + w / 2) * width)\n",
    "    ymax = int((y + h / 2) * height)\n",
    "    return class_index+\" \"+\" \".join([str(xmin), str(ymin), str(xmax), str(ymax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = glob.glob('RDD2022_all_countries/Norway/test/images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb6406b26d44e3fa8b4b6fc1005c617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "subm_file = open(\"submissiwe.txt\", \"w\")\n",
    "for file in tqdm(image_list):\n",
    "\n",
    "    basename = os.path.basename(file)\n",
    "    annot_name = basename.split(\".\")[0]+\".txt\"\n",
    "    annot_path = \"yolov7/runs/detect/preds_yolov7normal/labels/\"+annot_name\n",
    "    \n",
    "    with Image.open(file) as img:\n",
    "        width, height = img.size\n",
    "    \n",
    "    content = []\n",
    "    if os.path.exists(annot_path):\n",
    "        with open(annot_path, \"r\") as f:\n",
    "            data = [line.strip().split(\" \") for line in f.readlines()]\n",
    "            for elem in data:\n",
    "                content.append(convert_format(elem, width, height))\n",
    "    else:\n",
    "        content.append(\"\")\n",
    "        \n",
    "    subm_file.write(basename+\",\"+\" \".join(content)+\"\\n\")\n",
    "    \n",
    "subm_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_bounding_box(image_path, width, height):\n",
    "    img = cv2.imread(image_path)\n",
    "    dh, dw, _ = img.shape\n",
    "\n",
    "    split_string = image_path.split('\\\\')\n",
    "    \n",
    "\n",
    "    \n",
    "    label_path = '\\\\'.join((split_string[:2]))+'\\\\labels\\\\'+split_string[3].split('.')[0]+'.txt'\n",
    "    fl = open(label_path, 'r')\n",
    "    data = fl.readlines()\n",
    "    fl.close()\n",
    "\n",
    "    for dt in data:\n",
    "\n",
    "        # Split string to float\n",
    "        _, x, y, w, h = map(float, dt.split(' '))\n",
    "\n",
    "        # Taken from https://github.com/pjreddie/darknet/blob/810d7f797bdb2f021dbe65d2524c2ff6b8ab5c8b/src/image.c#L283-L291\n",
    "        # via https://stackoverflow.com/questions/44544471/how-to-get-the-coordinates-of-the-bounding-box-in-yolo-object-detection#comment102178409_44592380\n",
    "        l = int((x - w / 2) * dw)\n",
    "        r = int((x + w / 2) * dw)\n",
    "        t = int((y - h / 2) * dh)\n",
    "        b = int((y + h / 2) * dh)\n",
    "\n",
    "        if l < 0:\n",
    "            l = 0\n",
    "        if r > dw - 1:\n",
    "            r = dw - 1\n",
    "        if t < 0:\n",
    "            t = 0\n",
    "        if b > dh - 1:\n",
    "            b = dh - 1\n",
    "\n",
    "        cv2.rectangle(img, (l, t), (r, b), (0, 0, 255), 1)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bounding_box('dataset\\\\train\\\\images\\\\000015.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bounding_box('dataset\\\\train\\\\images\\\\000028.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bounding_box('dataset\\\\train\\\\images\\\\002008.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "515feadc005d0878886b1d3894f5409af9af7846eb0cb3518425ea0df708427b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
